{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ93q5vTku07"
      },
      "source": [
        "# CS 559  Project 2: Neural Network GridSearch Implementation\n",
        "### Name : Shrey Shah\n",
        "### CWID : 20009523"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJY02tPk2cZ"
      },
      "source": [
        "Task 1 [80]: Neural Network GridSearch Implementation\n",
        "Implement neural network grid search from scratch that tunes the hyperparameters (Number of\n",
        "neurons, hidden layers, batch size, etc.).\n",
        "ï‚· Other packages than NumPy are allowed but not in Neural Network Algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4-F9Wg9lKSQ"
      },
      "source": [
        "Task 2 [20]: Train Model\n",
        "*   Train your Neural Network GridSearch algorithm and report the result.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WHWhc8sbkyBq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Define the neural network architecture\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate):\n",
        "        # Initialize hyperparameters\n",
        "        self.input_size = input_size\n",
        "        self.hidden_sizes = list(hidden_sizes)  # Convert tuple to list\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        # Initialize weights and biases for each layer\n",
        "        sizes = [input_size] + self.hidden_sizes + [output_size]\n",
        "        self.weights = [np.random.randn(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
        "        self.biases = [np.random.randn(sizes[i+1]) for i in range(len(sizes)-1)]\n",
        "        \n",
        "    def train(self, X, y, epochs, batch_size):\n",
        "        # Train the neural network using mini-batch stochastic gradient descent\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(X.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            for i in range(0, X.shape[0], batch_size):\n",
        "                batch_indices = indices[i:i+batch_size]\n",
        "                X_batch = X[batch_indices]\n",
        "                y_batch = y[batch_indices]\n",
        "                self._update_weights(X_batch, y_batch)\n",
        "                \n",
        "    def _update_weights(self, X, y):\n",
        "        # Compute gradients of loss w.r.t. weights and biases using backpropagation\n",
        "        activations = [X]\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "            a = self._sigmoid(z)\n",
        "            activations.append(a)\n",
        "        error = (activations[-1] - y) / y.shape[0]\n",
        "        deltas = [error * self._sigmoid_derivative(activations[-1])]\n",
        "        for i in range(len(self.weights)-1, 0, -1):\n",
        "            delta = np.dot(deltas[-1], self.weights[i].T) * self._sigmoid_derivative(activations[i])\n",
        "            deltas.append(delta)\n",
        "        deltas.reverse()\n",
        "        \n",
        "        # Update weights and biases using gradients\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= self.learning_rate * np.dot(activations[i].T, deltas[i])\n",
        "            self.biases[i] -= self.learning_rate * np.sum(deltas[i], axis=0)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        # Use the trained neural network to predict classes for new data\n",
        "        activations = [X]\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "            a = self._sigmoid(z)\n",
        "            activations.append(a)\n",
        "        y_pred = activations[-1]\n",
        "        return y_pred\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def _sigmoid_derivative(self, a):\n",
        "        return a * (1 - a)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPIqvNJNeAnr",
        "outputId": "3157aff0-4737-4d35-af43-faead42c1a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Define the hyperparameters to tune\n",
        "input_size = 784\n",
        "hidden_sizes = [(3,), (5,), (10,),(15,),(100,)]\n",
        "output_size = 10\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(-1, 784) / 255.0\n",
        "X_test = X_test.reshape(-1, 784) / 255.0\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test = np.eye(10)[y_test]\n",
        "\n",
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "\n",
        "# Define the grid of hyperparameters to search over\n",
        "grid = {'hidden_sizes': hidden_sizes, 'batch_size': [16, 32,64,128,256,512,1024], 'learning_rate': [1,0.1, 0.01,0.001,0.0001]}\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAJXAngMeAbO",
        "outputId": "3dbc0a11-e1fc-41c6-f967-209c8d432d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hidden_sizes=(3,), batch_size=16, learning_rate=1, score=0.30525\n",
            "hidden_sizes=(3,), batch_size=16, learning_rate=0.1, score=0.3485\n",
            "hidden_sizes=(3,), batch_size=16, learning_rate=0.01, score=0.15066666666666667\n",
            "hidden_sizes=(3,), batch_size=16, learning_rate=0.001, score=0.10025\n",
            "hidden_sizes=(3,), batch_size=16, learning_rate=0.0001, score=0.098\n",
            "hidden_sizes=(3,), batch_size=32, learning_rate=1, score=0.29875\n",
            "hidden_sizes=(3,), batch_size=32, learning_rate=0.1, score=0.3739166666666667\n",
            "hidden_sizes=(3,), batch_size=32, learning_rate=0.01, score=0.14783333333333334\n",
            "hidden_sizes=(3,), batch_size=32, learning_rate=0.001, score=0.10475\n",
            "hidden_sizes=(3,), batch_size=32, learning_rate=0.0001, score=0.09716666666666667\n",
            "hidden_sizes=(3,), batch_size=64, learning_rate=1, score=0.5809166666666666\n",
            "hidden_sizes=(3,), batch_size=64, learning_rate=0.1, score=0.3175\n",
            "hidden_sizes=(3,), batch_size=64, learning_rate=0.01, score=0.2135\n",
            "hidden_sizes=(3,), batch_size=64, learning_rate=0.001, score=0.10383333333333333\n",
            "hidden_sizes=(3,), batch_size=64, learning_rate=0.0001, score=0.08391666666666667\n",
            "hidden_sizes=(3,), batch_size=128, learning_rate=1, score=0.5891666666666666\n",
            "hidden_sizes=(3,), batch_size=128, learning_rate=0.1, score=0.18216666666666667\n",
            "hidden_sizes=(3,), batch_size=128, learning_rate=0.01, score=0.13941666666666666\n",
            "hidden_sizes=(3,), batch_size=128, learning_rate=0.001, score=0.092\n",
            "hidden_sizes=(3,), batch_size=128, learning_rate=0.0001, score=0.1105\n",
            "hidden_sizes=(3,), batch_size=256, learning_rate=1, score=0.21691666666666667\n",
            "hidden_sizes=(3,), batch_size=256, learning_rate=0.1, score=0.16141666666666668\n",
            "hidden_sizes=(3,), batch_size=256, learning_rate=0.01, score=0.17\n",
            "hidden_sizes=(3,), batch_size=256, learning_rate=0.001, score=0.09783333333333333\n",
            "hidden_sizes=(3,), batch_size=256, learning_rate=0.0001, score=0.12541666666666668\n",
            "hidden_sizes=(3,), batch_size=512, learning_rate=1, score=0.29108333333333336\n",
            "hidden_sizes=(3,), batch_size=512, learning_rate=0.1, score=0.15716666666666668\n",
            "hidden_sizes=(3,), batch_size=512, learning_rate=0.01, score=0.098\n",
            "hidden_sizes=(3,), batch_size=512, learning_rate=0.001, score=0.11025\n",
            "hidden_sizes=(3,), batch_size=512, learning_rate=0.0001, score=0.08675\n",
            "hidden_sizes=(3,), batch_size=1024, learning_rate=1, score=0.3315\n",
            "hidden_sizes=(3,), batch_size=1024, learning_rate=0.1, score=0.12475\n",
            "hidden_sizes=(3,), batch_size=1024, learning_rate=0.01, score=0.12483333333333334\n",
            "hidden_sizes=(3,), batch_size=1024, learning_rate=0.001, score=0.078\n",
            "hidden_sizes=(3,), batch_size=1024, learning_rate=0.0001, score=0.10058333333333333\n",
            "hidden_sizes=(5,), batch_size=16, learning_rate=1, score=0.83275\n",
            "hidden_sizes=(5,), batch_size=16, learning_rate=0.1, score=0.5460833333333334\n",
            "hidden_sizes=(5,), batch_size=16, learning_rate=0.01, score=0.2735\n",
            "hidden_sizes=(5,), batch_size=16, learning_rate=0.001, score=0.19383333333333333\n",
            "hidden_sizes=(5,), batch_size=16, learning_rate=0.0001, score=0.07933333333333334\n",
            "hidden_sizes=(5,), batch_size=32, learning_rate=1, score=0.8573333333333333\n",
            "hidden_sizes=(5,), batch_size=32, learning_rate=0.1, score=0.51725\n",
            "hidden_sizes=(5,), batch_size=32, learning_rate=0.01, score=0.16516666666666666\n",
            "hidden_sizes=(5,), batch_size=32, learning_rate=0.001, score=0.10416666666666667\n",
            "hidden_sizes=(5,), batch_size=32, learning_rate=0.0001, score=0.09458333333333334\n",
            "hidden_sizes=(5,), batch_size=64, learning_rate=1, score=0.8358333333333333\n",
            "hidden_sizes=(5,), batch_size=64, learning_rate=0.1, score=0.36141666666666666\n",
            "hidden_sizes=(5,), batch_size=64, learning_rate=0.01, score=0.1565\n",
            "hidden_sizes=(5,), batch_size=64, learning_rate=0.001, score=0.057916666666666665\n",
            "hidden_sizes=(5,), batch_size=64, learning_rate=0.0001, score=0.10583333333333333\n",
            "hidden_sizes=(5,), batch_size=128, learning_rate=1, score=0.6455\n",
            "hidden_sizes=(5,), batch_size=128, learning_rate=0.1, score=0.2975\n",
            "hidden_sizes=(5,), batch_size=128, learning_rate=0.01, score=0.16891666666666666\n",
            "hidden_sizes=(5,), batch_size=128, learning_rate=0.001, score=0.08983333333333333\n",
            "hidden_sizes=(5,), batch_size=128, learning_rate=0.0001, score=0.08858333333333333\n",
            "hidden_sizes=(5,), batch_size=256, learning_rate=1, score=0.5196666666666667\n",
            "hidden_sizes=(5,), batch_size=256, learning_rate=0.1, score=0.24008333333333334\n",
            "hidden_sizes=(5,), batch_size=256, learning_rate=0.01, score=0.13433333333333333\n",
            "hidden_sizes=(5,), batch_size=256, learning_rate=0.001, score=0.10841666666666666\n",
            "hidden_sizes=(5,), batch_size=256, learning_rate=0.0001, score=0.06283333333333334\n",
            "hidden_sizes=(5,), batch_size=512, learning_rate=1, score=0.517\n",
            "hidden_sizes=(5,), batch_size=512, learning_rate=0.1, score=0.16458333333333333\n",
            "hidden_sizes=(5,), batch_size=512, learning_rate=0.01, score=0.15775\n",
            "hidden_sizes=(5,), batch_size=512, learning_rate=0.001, score=0.14675\n",
            "hidden_sizes=(5,), batch_size=512, learning_rate=0.0001, score=0.07966666666666666\n",
            "hidden_sizes=(5,), batch_size=1024, learning_rate=1, score=0.30241666666666667\n",
            "hidden_sizes=(5,), batch_size=1024, learning_rate=0.1, score=0.17291666666666666\n",
            "hidden_sizes=(5,), batch_size=1024, learning_rate=0.01, score=0.1035\n",
            "hidden_sizes=(5,), batch_size=1024, learning_rate=0.001, score=0.07433333333333333\n",
            "hidden_sizes=(5,), batch_size=1024, learning_rate=0.0001, score=0.14708333333333334\n",
            "hidden_sizes=(10,), batch_size=16, learning_rate=1, score=0.9056666666666666\n",
            "hidden_sizes=(10,), batch_size=16, learning_rate=0.1, score=0.8345833333333333\n",
            "hidden_sizes=(10,), batch_size=16, learning_rate=0.01, score=0.31233333333333335\n",
            "hidden_sizes=(10,), batch_size=16, learning_rate=0.001, score=0.2025\n",
            "hidden_sizes=(10,), batch_size=16, learning_rate=0.0001, score=0.10991666666666666\n",
            "hidden_sizes=(10,), batch_size=32, learning_rate=1, score=0.9056666666666666\n",
            "hidden_sizes=(10,), batch_size=32, learning_rate=0.1, score=0.6959166666666666\n",
            "hidden_sizes=(10,), batch_size=32, learning_rate=0.01, score=0.26158333333333333\n",
            "hidden_sizes=(10,), batch_size=32, learning_rate=0.001, score=0.14841666666666667\n",
            "hidden_sizes=(10,), batch_size=32, learning_rate=0.0001, score=0.133\n",
            "hidden_sizes=(10,), batch_size=64, learning_rate=1, score=0.8741666666666666\n",
            "hidden_sizes=(10,), batch_size=64, learning_rate=0.1, score=0.5323333333333333\n",
            "hidden_sizes=(10,), batch_size=64, learning_rate=0.01, score=0.19775\n",
            "hidden_sizes=(10,), batch_size=64, learning_rate=0.001, score=0.09833333333333333\n",
            "hidden_sizes=(10,), batch_size=64, learning_rate=0.0001, score=0.09716666666666667\n",
            "hidden_sizes=(10,), batch_size=128, learning_rate=1, score=0.8415\n",
            "hidden_sizes=(10,), batch_size=128, learning_rate=0.1, score=0.40116666666666667\n",
            "hidden_sizes=(10,), batch_size=128, learning_rate=0.01, score=0.16191666666666665\n",
            "hidden_sizes=(10,), batch_size=128, learning_rate=0.001, score=0.08983333333333333\n",
            "hidden_sizes=(10,), batch_size=128, learning_rate=0.0001, score=0.14441666666666667\n",
            "hidden_sizes=(10,), batch_size=256, learning_rate=1, score=0.5871666666666666\n",
            "hidden_sizes=(10,), batch_size=256, learning_rate=0.1, score=0.21975\n",
            "hidden_sizes=(10,), batch_size=256, learning_rate=0.01, score=0.11041666666666666\n",
            "hidden_sizes=(10,), batch_size=256, learning_rate=0.001, score=0.07591666666666666\n",
            "hidden_sizes=(10,), batch_size=256, learning_rate=0.0001, score=0.07258333333333333\n",
            "hidden_sizes=(10,), batch_size=512, learning_rate=1, score=0.58475\n",
            "hidden_sizes=(10,), batch_size=512, learning_rate=0.1, score=0.17016666666666666\n",
            "hidden_sizes=(10,), batch_size=512, learning_rate=0.01, score=0.13025\n",
            "hidden_sizes=(10,), batch_size=512, learning_rate=0.001, score=0.12916666666666668\n",
            "hidden_sizes=(10,), batch_size=512, learning_rate=0.0001, score=0.1005\n",
            "hidden_sizes=(10,), batch_size=1024, learning_rate=1, score=0.44725\n",
            "hidden_sizes=(10,), batch_size=1024, learning_rate=0.1, score=0.10883333333333334\n",
            "hidden_sizes=(10,), batch_size=1024, learning_rate=0.01, score=0.09908333333333333\n",
            "hidden_sizes=(10,), batch_size=1024, learning_rate=0.001, score=0.08733333333333333\n",
            "hidden_sizes=(10,), batch_size=1024, learning_rate=0.0001, score=0.12883333333333333\n",
            "hidden_sizes=(15,), batch_size=16, learning_rate=1, score=0.9274166666666667\n",
            "hidden_sizes=(15,), batch_size=16, learning_rate=0.1, score=0.8473333333333334\n",
            "hidden_sizes=(15,), batch_size=16, learning_rate=0.01, score=0.3475\n",
            "hidden_sizes=(15,), batch_size=16, learning_rate=0.001, score=0.15791666666666668\n",
            "hidden_sizes=(15,), batch_size=16, learning_rate=0.0001, score=0.12533333333333332\n",
            "hidden_sizes=(15,), batch_size=32, learning_rate=1, score=0.9135833333333333\n",
            "hidden_sizes=(15,), batch_size=32, learning_rate=0.1, score=0.75275\n",
            "hidden_sizes=(15,), batch_size=32, learning_rate=0.01, score=0.2806666666666667\n",
            "hidden_sizes=(15,), batch_size=32, learning_rate=0.001, score=0.11433333333333333\n",
            "hidden_sizes=(15,), batch_size=32, learning_rate=0.0001, score=0.11658333333333333\n",
            "hidden_sizes=(15,), batch_size=64, learning_rate=1, score=0.8974166666666666\n",
            "hidden_sizes=(15,), batch_size=64, learning_rate=0.1, score=0.6545833333333333\n",
            "hidden_sizes=(15,), batch_size=64, learning_rate=0.01, score=0.1745\n",
            "hidden_sizes=(15,), batch_size=64, learning_rate=0.001, score=0.09791666666666667\n",
            "hidden_sizes=(15,), batch_size=64, learning_rate=0.0001, score=0.07908333333333334\n",
            "hidden_sizes=(15,), batch_size=128, learning_rate=1, score=0.77525\n",
            "hidden_sizes=(15,), batch_size=128, learning_rate=0.1, score=0.43566666666666665\n",
            "hidden_sizes=(15,), batch_size=128, learning_rate=0.01, score=0.18158333333333335\n",
            "hidden_sizes=(15,), batch_size=128, learning_rate=0.001, score=0.11841666666666667\n",
            "hidden_sizes=(15,), batch_size=128, learning_rate=0.0001, score=0.09816666666666667\n",
            "hidden_sizes=(15,), batch_size=256, learning_rate=1, score=0.7555833333333334\n",
            "hidden_sizes=(15,), batch_size=256, learning_rate=0.1, score=0.3428333333333333\n",
            "hidden_sizes=(15,), batch_size=256, learning_rate=0.01, score=0.18533333333333332\n",
            "hidden_sizes=(15,), batch_size=256, learning_rate=0.001, score=0.10108333333333333\n",
            "hidden_sizes=(15,), batch_size=256, learning_rate=0.0001, score=0.12366666666666666\n",
            "hidden_sizes=(15,), batch_size=512, learning_rate=1, score=0.7165\n",
            "hidden_sizes=(15,), batch_size=512, learning_rate=0.1, score=0.24783333333333332\n",
            "hidden_sizes=(15,), batch_size=512, learning_rate=0.01, score=0.11175\n",
            "hidden_sizes=(15,), batch_size=512, learning_rate=0.001, score=0.11291666666666667\n",
            "hidden_sizes=(15,), batch_size=512, learning_rate=0.0001, score=0.10216666666666667\n",
            "hidden_sizes=(15,), batch_size=1024, learning_rate=1, score=0.5023333333333333\n",
            "hidden_sizes=(15,), batch_size=1024, learning_rate=0.1, score=0.09791666666666667\n",
            "hidden_sizes=(15,), batch_size=1024, learning_rate=0.01, score=0.09891666666666667\n",
            "hidden_sizes=(15,), batch_size=1024, learning_rate=0.001, score=0.11966666666666667\n",
            "hidden_sizes=(15,), batch_size=1024, learning_rate=0.0001, score=0.09541666666666666\n",
            "hidden_sizes=(100,), batch_size=16, learning_rate=1, score=0.7731666666666667\n",
            "hidden_sizes=(100,), batch_size=16, learning_rate=0.1, score=0.53\n",
            "hidden_sizes=(100,), batch_size=16, learning_rate=0.01, score=0.22441666666666665\n",
            "hidden_sizes=(100,), batch_size=16, learning_rate=0.001, score=0.15241666666666667\n",
            "hidden_sizes=(100,), batch_size=16, learning_rate=0.0001, score=0.17333333333333334\n",
            "hidden_sizes=(100,), batch_size=32, learning_rate=1, score=0.6806666666666666\n",
            "hidden_sizes=(100,), batch_size=32, learning_rate=0.1, score=0.439\n",
            "hidden_sizes=(100,), batch_size=32, learning_rate=0.01, score=0.19241666666666668\n",
            "hidden_sizes=(100,), batch_size=32, learning_rate=0.001, score=0.09883333333333333\n",
            "hidden_sizes=(100,), batch_size=32, learning_rate=0.0001, score=0.08683333333333333\n",
            "hidden_sizes=(100,), batch_size=64, learning_rate=1, score=0.46058333333333334\n",
            "hidden_sizes=(100,), batch_size=64, learning_rate=0.1, score=0.46658333333333335\n",
            "hidden_sizes=(100,), batch_size=64, learning_rate=0.01, score=0.244\n",
            "hidden_sizes=(100,), batch_size=64, learning_rate=0.001, score=0.08816666666666667\n",
            "hidden_sizes=(100,), batch_size=64, learning_rate=0.0001, score=0.067\n",
            "hidden_sizes=(100,), batch_size=128, learning_rate=1, score=0.5665833333333333\n",
            "hidden_sizes=(100,), batch_size=128, learning_rate=0.1, score=0.488\n",
            "hidden_sizes=(100,), batch_size=128, learning_rate=0.01, score=0.09191666666666666\n",
            "hidden_sizes=(100,), batch_size=128, learning_rate=0.001, score=0.08725\n",
            "hidden_sizes=(100,), batch_size=128, learning_rate=0.0001, score=0.104\n",
            "hidden_sizes=(100,), batch_size=256, learning_rate=1, score=0.617\n",
            "hidden_sizes=(100,), batch_size=256, learning_rate=0.1, score=0.09658333333333333\n",
            "hidden_sizes=(100,), batch_size=256, learning_rate=0.01, score=0.09791666666666667\n",
            "hidden_sizes=(100,), batch_size=256, learning_rate=0.001, score=0.1035\n",
            "hidden_sizes=(100,), batch_size=256, learning_rate=0.0001, score=0.11066666666666666\n",
            "hidden_sizes=(100,), batch_size=512, learning_rate=1, score=0.5690833333333334\n",
            "hidden_sizes=(100,), batch_size=512, learning_rate=0.1, score=0.16391666666666665\n",
            "hidden_sizes=(100,), batch_size=512, learning_rate=0.01, score=0.10825\n",
            "hidden_sizes=(100,), batch_size=512, learning_rate=0.001, score=0.09608333333333334\n",
            "hidden_sizes=(100,), batch_size=512, learning_rate=0.0001, score=0.06341666666666666\n",
            "hidden_sizes=(100,), batch_size=1024, learning_rate=1, score=0.3501666666666667\n",
            "hidden_sizes=(100,), batch_size=1024, learning_rate=0.1, score=0.16083333333333333\n",
            "hidden_sizes=(100,), batch_size=1024, learning_rate=0.01, score=0.08175\n",
            "hidden_sizes=(100,), batch_size=1024, learning_rate=0.001, score=0.09375\n",
            "hidden_sizes=(100,), batch_size=1024, learning_rate=0.0001, score=0.10908333333333334\n",
            "Best score: 0.9274166666666667, Best params: {'hidden_sizes': (15,), 'batch_size': 16, 'learning_rate': 1}\n"
          ]
        }
      ],
      "source": [
        "# Define a function to perform grid search\n",
        "def grid_search(X, y, X_val,y_val,grid, epochs):\n",
        "    best_score = 0.0\n",
        "    best_params = None\n",
        "    for hidden_sizes in grid['hidden_sizes']:\n",
        "        for batch_size in grid['batch_size']:\n",
        "            for learning_rate in grid['learning_rate']:\n",
        "                nn = NeuralNetwork(input_size, hidden_sizes, output_size, learning_rate)\n",
        "                nn.train(X, y, epochs, batch_size)\n",
        "                y_pred = nn.predict(X_val)\n",
        "                score = np.mean(np.argmax(y_val ,axis=1) == np.argmax(y_pred, axis=1))\n",
        "                print(f'hidden_sizes={hidden_sizes}, batch_size={batch_size}, learning_rate={learning_rate}, score={score}')\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_params = {'hidden_sizes': hidden_sizes, 'batch_size': batch_size, 'learning_rate': learning_rate}\n",
        "    return best_params, best_score\n",
        "\n",
        "# Perform grid search\n",
        "best_params, best_score = grid_search(X, y,X_val,y_val ,grid, epochs)\n",
        "print(f'Best score: {best_score}, Best params: {best_params}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq-rB9U1GJtK",
        "outputId": "8999eb25-90b9-4aaa-814f-b7224fd547df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set accuracy: 0.9202\n"
          ]
        }
      ],
      "source": [
        "# Create a new instance of NeuralNetwork with the best parameters\n",
        "nn = NeuralNetwork(input_size, best_params['hidden_sizes'], output_size, best_params['learning_rate'])\n",
        "\n",
        "# Train the model on the entire training set\n",
        "nn.train(X_train, y_train, epochs, best_params['batch_size'])\n",
        "\n",
        "# Use the trained model to predict classes for the test set\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Compute the accuracy of the model on the test set\n",
        "accuracy = np.mean(np.argmax(y_test, axis=1) == np.argmax(y_pred, axis=1))\n",
        "print(f'Test set accuracy: {accuracy}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
